{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Scripts.util import Preprocessing,SentenceSplitter\n",
    "from sinling import SinhalaTokenizer\n",
    "import kaggle\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kavishaabeynayaka/sinhala-fg-ner\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files(\"kavishaabeynayaka/sinhala-fg-ner\", path='../AnanyaSinhalaNERDataset/combined_data', unzip=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: ['/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_13_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_10_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_4_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_14_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_1_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_11_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_7_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_12_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_5_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_8_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_15_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_2_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_9_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_6_combined.tsv', '/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/partition_3_combined.tsv']\n",
      "[         Token Postag Nertag\n",
      "0     ජනාධිපති    NNC      O\n",
      "1       එම්බකි    NNP  B-PER\n",
      "2        දෙවනි    NNC      O\n",
      "3           හා     CC      O\n",
      "4        අවසාන     JJ      O\n",
      "...        ...    ...    ...\n",
      "7397  හිමියන්ට    NNC      O\n",
      "7398   හැකියාව    NNC      O\n",
      "7399      ලැබී    VNF      O\n",
      "7400        ඇත    NIP      O\n",
      "7401         .     FS      O\n",
      "\n",
      "[7402 rows x 3 columns],              Token Postag Nertag\n",
      "0              එදා    NNC      O\n",
      "1           බිහිවූ     VP      O\n",
      "2     මොඑරිතීරියම්    NNP      O\n",
      "3               ගේ     CM      O\n",
      "4              සිට   POST      O\n",
      "...            ...    ...    ...\n",
      "8539       මැතිවරණ    NNJ  I-ORG\n",
      "8540        කොමිසම    NNC  I-ORG\n",
      "8541          කියා    VNF      O\n",
      "8542            ඇත    NIP      O\n",
      "8543             .     FS      O\n",
      "\n",
      "[8544 rows x 3 columns],           Token Postag Nertag\n",
      "0          මේවා    PRP      O\n",
      "1         තහනම්    JCV      O\n",
      "2       එක්‌සත්    VNF  B-ORG\n",
      "3      ජාතීන්ගේ    NNP  I-ORG\n",
      "4     යෝජනාවක්‌    NNC      O\n",
      "...         ...    ...    ...\n",
      "5452    හරිහැටි     RB      O\n",
      "5453     නොලැබී    VNF      O\n",
      "5454        ඇති    NIP      O\n",
      "5455        බවය    NVB      O\n",
      "5456          .     FS      O\n",
      "\n",
      "[5457 rows x 3 columns],             Token Postag Nertag\n",
      "0        කොයින්ස්    NNP  B-ORG\n",
      "1          වෙතින්   POST      O\n",
      "2     ස්ට්‍රෝබෙරි    NNP      O\n",
      "3             බීර    NNP      O\n",
      "4           ත්‍රී     JJ  B-ORG\n",
      "...           ...    ...    ...\n",
      "7728    ඊශ්රායලයට    NNP  B-LOC\n",
      "7729          ඇති    NIP      O\n",
      "7730           බව   POST      O\n",
      "7731            ය     RP      O\n",
      "7732            .     FS      O\n",
      "\n",
      "[7733 rows x 3 columns],                  Token Postag Nertag\n",
      "0                එහිදී    PRP      O\n",
      "1     මහේස්ත්‍රාත්වරයා    NNC      O\n",
      "2               විසින්   POST      O\n",
      "3                  දෙන     VP      O\n",
      "4                   ලද     VP      O\n",
      "...                ...    ...    ...\n",
      "5665             ශ්‍රී    NNP  B-LOC\n",
      "5666              ලංකා    NNP  I-LOC\n",
      "5667          කණ්ඩායමට    NNC      O\n",
      "5668           සිදුවිය    VFM      O\n",
      "5669                 .     FS      O\n",
      "\n",
      "[5670 rows x 3 columns],              Token Postag Nertag\n",
      "0           මහනුවර    NNP  B-LOC\n",
      "1           ගලගෙදර    NNP  I-LOC\n",
      "2           මැදගොඩ    NNP  B-ORG\n",
      "3            ශ්‍රී    NNP  I-ORG\n",
      "4     සිද්ධාර්ථෝදය    NNP  I-ORG\n",
      "...            ...    ...    ...\n",
      "5902        පැපුවා    NNP  B-LOC\n",
      "5903    නිව්ගිනියා    NNP  I-LOC\n",
      "5904           රජය    NNC  B-ORG\n",
      "5905         පවසයි    VFM      O\n",
      "5906             .     FS      O\n",
      "\n",
      "[5907 rows x 3 columns],       Token Postag Nertag\n",
      "0     ආනයනය    NCV      O\n",
      "1       කරන     VP      O\n",
      "2        ලද     VP      O\n",
      "3      වාහන    NNC      O\n",
      "4      අමතර     JJ      O\n",
      "...     ...    ...    ...\n",
      "5378      ක     RP      O\n",
      "5379   තහනම    NNC      O\n",
      "5380   ඉවත්  RRPCV      O\n",
      "5381    කළා    VFM      O\n",
      "5382      .     FS      O\n",
      "\n",
      "[5383 rows x 3 columns],                 Token Postag Nertag\n",
      "0            පනාවිටිය    NNC  B-LOC\n",
      "1              අම්බලම    NNP  I-LOC\n",
      "2            කුරුණෑගල    NNP  I-LOC\n",
      "3     දිස්ති‍්‍රක්කයේ    NNC  I-LOC\n",
      "4            මැටියගනේ     VP  I-LOC\n",
      "...               ...    ...    ...\n",
      "7266          අනතුරක්    NNC      O\n",
      "7267             සිදු   RPCV      O\n",
      "7268             වුණු     VP      O\n",
      "7269           පසුවයි    VFM      O\n",
      "7270                .     FS      O\n",
      "\n",
      "[7271 rows x 3 columns],             Token Postag Nertag\n",
      "0           දේශීය     JJ      O\n",
      "1          වෛද්‍ය     JJ      O\n",
      "2     නිෂ්පාදනයන්    NNC      O\n",
      "3         පිළිබඳව   POST      O\n",
      "4         පර්යේෂණ    NCV      O\n",
      "...           ...    ...    ...\n",
      "4537          ඇති    NIP      O\n",
      "4538         බවත්   POST      O\n",
      "4539       වාර්තා    NCV      O\n",
      "4540           වේ    VFM      O\n",
      "4541            .     FS      O\n",
      "\n",
      "[4542 rows x 3 columns],              Token Postag Nertag\n",
      "0              කේ.    NNP  B-PER\n",
      "1     මිත්‍රරත්නගේ    NNP  I-PER\n",
      "2           ‘‘කිරි    NNP      O\n",
      "3             පැණි    NNP      O\n",
      "4         නාට්‍යයේ    NNC      O\n",
      "...            ...    ...    ...\n",
      "9031          යාමට    VNN      O\n",
      "9032           මෙම    DET      O\n",
      "9033        සත්වයෝ    NNC      O\n",
      "9034       පෙළඹෙති    VFM      O\n",
      "9035             .     FS      O\n",
      "\n",
      "[9036 rows x 3 columns],          Token Postag Nertag\n",
      "0          මෙය    PRP      O\n",
      "1      ඊශ්රායල    NNP  B-LOC\n",
      "2     ප්‍රහාරය    NNC      O\n",
      "3       යුක්ති    NCV      O\n",
      "4         සහගත     VP      O\n",
      "...        ...    ...    ...\n",
      "3795       ගැන   POST      O\n",
      "3796      සමාව    NCV      O\n",
      "3797       යැද    VNF      O\n",
      "3798      තිබේ    VFM      O\n",
      "3799         .     FS      O\n",
      "\n",
      "[3800 rows x 3 columns],             Token Postag Nertag\n",
      "0        නවසීලන්ත    NNP  B-LOC\n",
      "1          සංචාරය    NNC      O\n",
      "2             මෑත     JJ      O\n",
      "3        ඉතිහාසයේ    NNC      O\n",
      "4           ශ්‍රී    NNP  B-LOC\n",
      "...           ...    ...    ...\n",
      "5617    දැනගැනීමේ    VNN      O\n",
      "5618  අපේක්ෂාවෙන්    NNC      O\n",
      "5619        පසුවන     VP      O\n",
      "5620         බවයි    NVB      O\n",
      "5621            .     FS      O\n",
      "\n",
      "[5622 rows x 3 columns],           Token Postag Nertag\n",
      "0         පාරුව    NNC      O\n",
      "1        අනතුරට    NNC      O\n",
      "2         පත්වූ     VP      O\n",
      "3        සැණින්    NNC      O\n",
      "4           අසල   POST      O\n",
      "...         ...    ...    ...\n",
      "8752     සිනෙත්    NNP  B-PER\n",
      "8753    මධුෂාන්    NNP  I-PER\n",
      "8754  කුමාරසිංහ    NNP  I-PER\n",
      "8755    (සීමිත)    UNK      O\n",
      "8756          .     FS      O\n",
      "\n",
      "[8757 rows x 3 columns],               Token Postag Nertag\n",
      "0             මාතලේ    NNP  B-LOC\n",
      "1                වී    VNF      O\n",
      "2          අස්වැන්න    VNN      O\n",
      "3     සම්පූර්ණයෙන්ම    NNC      O\n",
      "4              ‍මෙම    DET      O\n",
      "...             ...    ...    ...\n",
      "5529            6දා    NNP      O\n",
      "5530         කොළඹදී    NNP  B-LOC\n",
      "5531     පැවැත්වීමට    VNN      O\n",
      "5532        නියමිතය    NVB      O\n",
      "5533              .     FS      O\n",
      "\n",
      "[5534 rows x 3 columns],               Token Postag Nertag\n",
      "0                එම    DET      O\n",
      "1             පිරිස    NNC      O\n",
      "2        පුදුචෙරිහි    NNP  B-LOC\n",
      "3               සිට   POST      O\n",
      "4     ඕස්ට්‍රේලියාව    NNP  B-LOC\n",
      "...             ...    ...    ...\n",
      "5410          මාතලේ    NNP  B-LOC\n",
      "5411          ලග්ගල    NNP  I-LOC\n",
      "5412      ප්‍රදේශයේ    NNC      O\n",
      "5413        ස්ථාපිත    JCV      O\n",
      "5414         කිරීමට    VNN      O\n",
      "\n",
      "[5415 rows x 3 columns]]\n",
      "(96073, 3)\n",
      "Training set size: 57643\n",
      "Validation set size: 19215\n",
      "Testing set size: 19215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load multiple TSV files\n",
    "file_paths = glob.glob('/home/kavisha/Research/AnanyaSinhalaNERDataset/combined_data/*.tsv')  #\n",
    "\n",
    "\n",
    "print(\"Files found:\", file_paths)  \n",
    "\n",
    "\n",
    "if not file_paths:\n",
    "    print(\"No TSV files found. Please check the path.\")\n",
    "else:\n",
    "\n",
    "    dataframes = []\n",
    "    for file in file_paths:\n",
    "        df = pd.read_csv(file, sep='\\t',names=[\"Token\",\"Postag\",\"Nertag\"])\n",
    "        preprocessing = Preprocessing(df)\n",
    "        cleaned_df = preprocessing.apply_preprocessing()\n",
    "  \n",
    "        if not df.empty:  \n",
    "            dataframes.append(cleaned_df)\n",
    "        else:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "    print(dataframes)\n",
    "    if dataframes:\n",
    "        data = pd.concat(dataframes, axis=0)\n",
    "        print(data.shape)\n",
    "        train_data, temp_data = train_test_split(data, test_size=0.4,shuffle=False)\n",
    "     \n",
    "        val_data, test_data = train_test_split(temp_data, test_size=0.5,shuffle=False)\n",
    "\n",
    "       \n",
    "        print(\"Training set size:\", len(train_data))\n",
    "        print(\"Validation set size:\", len(val_data))\n",
    "        print(\"Testing set size:\", len(test_data))\n",
    "\n",
    "        train_data.to_csv('/home/kavisha/Research/combined_data/train.tsv', sep='\\t', index=False)\n",
    "        val_data.to_csv('/home/kavisha/Research/combined_data/validation.tsv', sep='\\t', index=False)\n",
    "        test_data.to_csv('/home/kavisha/Research/combined_data/est.tsv', sep='\\t', index=False)\n",
    "    else:\n",
    "        print(\"No valid dataframes to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/kavisha/Research/combined_data/train.tsv\",sep=\"\\t\")\n",
    "train_data.shape\n",
    "train_data.head\n",
    "train_splitter =  SentenceSplitter(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentences(df):\n",
    "    # Remove rows where 'Token' or 'Postag' columns contain empty strings\n",
    "    # Drop rows with any NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    sentences = []\n",
    "    for _, sentence_df in df.groupby(\"SentenceID\"):\n",
    "        sentence = list(sentence_df[['Token', 'Postag', 'Nertag']].itertuples(index=False, name=None))\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "train_sents =  prepare_sentences(train_splitter.split_sentences())\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "# X_test = [sent2features(s) for s in test_sents]\n",
    "# y_test = [sent2labels(s) for s in test_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 717 ms, sys: 3.66 ms, total: 721 ms\n",
      "Wall time: 720 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('SinBaseCRF.crfsuite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
